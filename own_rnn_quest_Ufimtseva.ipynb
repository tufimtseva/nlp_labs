{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e02174-3ce0-4d37-9072-54a5a9229490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8222c8-d159-410d-ac59-bec860e392ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Vocabulary:\n",
    "\n",
    "  def __init__(self, tokens, unk_token=\"<unk>\", min_count=None):\n",
    "    if min_count is None:\n",
    "      min_count = 0\n",
    "    count = collections.Counter(tokens)\n",
    "    tokens = [w for w, c in count.most_common() if c >= min_count] # added\n",
    "\n",
    "\n",
    "    self.unk_token = unk_token\n",
    "    self.unk_index = 0\n",
    "    self._itos = [unk_token] + tokens\n",
    "    self._stoi = {token: index for index, token in enumerate(self._itos)}\n",
    "\n",
    "  def stoi(self, token: str) -> int:\n",
    "    return self._stoi.get(token, self.unk_index)\n",
    "\n",
    "\n",
    "  def itos(self, index: int) -> str:\n",
    "    if index < 0 or index >= len(self._itos):\n",
    "      raise LookupError(f\"Index {index} out of range for vocabulary size {len(self._itos)}\")\n",
    "    return self._itos[index]\n",
    "\n",
    "  @property\n",
    "  def tokens(self):\n",
    "    return self._itos\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self._itos)\n",
    "\n",
    "  def __getitem__(self, key):\n",
    "    if isinstance(key, str):\n",
    "      return self.stoi(key)\n",
    "    elif isinstance(key, int):\n",
    "      return self.itos(key)\n",
    "    else:\n",
    "      TypeError(\"Unsupported ley type\")\n",
    "\n",
    "def vectorize(tokens, vocab):\n",
    "  return torch.tensor([vocab.stoi(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19beacc-080c-4d26-9b3c-8112f42bc317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_target(tokens, seq_length):\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(0, len(tokens) - seq_length):\n",
    "        context = tokens[i: i + seq_length]              \n",
    "        target = tokens[i + 1: i + seq_length + 1]        \n",
    "        contexts.append(context)\n",
    "        targets.append(target)\n",
    "    return contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c655f049-efeb-4ecd-8bbe-6b853b046585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['h', 'e', 'l', 'l']], [['e', 'l', 'l', 'o']])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_context_target(list(\"Hello\".lower()), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d838c4a-18a1-4e7d-8251-636d6e3c3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8baf4de8-8933-4945-8fd1-9d05be5c3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfed6550-ca9e-41de-bf68-4150b8d001aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX][Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"[Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX]\" * 20\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fbd5776-9f0a-45da-acf1-73b2dd23af86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize(text)\n",
    "vocab = Vocabulary(tokens)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47539271-8f38-4154-882c-a4a79bd770c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa0e33c-0042-4faf-a9f1-c4aef998f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmanRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.W_h = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.U_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.W_y = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, hidden_state=None):\n",
    "        batch_size, seq_len = inputs.size()\n",
    "        if hidden_state is None:\n",
    "            hidden_state = torch.zeros(batch_size, self.hidden_dim, device=inputs.device)\n",
    "\n",
    "        log_probs_seq = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = self.embeddings(inputs[:, t])  \n",
    "            hidden_state = self.tanh(self.W_h(x_t) + self.U_h(hidden_state))  \n",
    "            logits = self.W_y(hidden_state)  \n",
    "            log_probs = torch.log_softmax(logits, dim=-1)\n",
    "            log_probs_seq.append(log_probs)\n",
    "\n",
    "        log_probs_seq = torch.stack(log_probs_seq, dim=1)\n",
    "        return log_probs_seq, hidden_state\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba47ff5a-607f-4b03-a0be-555e88d6738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, tokens, vocab, context_size, loss_fn, optimizer):\n",
    "    contexts, targets = build_context_target(tokens, context_size)  \n",
    "    total_loss = 0.0\n",
    "    total_sequences = len(targets)\n",
    "    total_batch_num = (total_sequences // params[\"batch_size\"]) + (1 if total_sequences % params[\"batch_size\"] != 0 else 0)\n",
    "\n",
    "    for context_batch, target_batch in tqdm(zip(batchify(contexts, params[\"batch_size\"]), batchify(targets, params[\"batch_size\"])),\n",
    "                                            total=total_batch_num):\n",
    "        X = torch.stack([vectorize(context, vocab) for context in context_batch]).to(device)  \n",
    "        Y = torch.stack([vectorize(target, vocab) for target in target_batch]).to(device)  \n",
    "        \n",
    "        hidden_state = model.init_hidden(batch_size=X.size(0)).to(X.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_probs, hidden_state = model(X, hidden_state)\n",
    "\n",
    "        loss = loss_fn(log_probs.view(-1, model.vocab_size), Y.view(-1))\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / total_sequences\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "598cab81-42a0-43da-bfbd-7df55287b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tokens, vocab, context_size, loss_fn, optimizer):\n",
    "  for e in range(params[\"num_epochs\"]):\n",
    "    print(\"EPOCH :\", e, \"/\",params[\"num_epochs\"])\n",
    "    avg_loss = train_loop(model, tokens, vocab, context_size, loss_fn, optimizer)\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f86d869a-b5af-4527-9cd2-225394bf391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_decode(model, vocab, start_token, end_token):\n",
    "    start_index = vocab.stoi(start_token)\n",
    "    result = [start_index]\n",
    "    hidden_state = model.init_hidden(batch_size=1)  \n",
    "    while len(result) < 100:  \n",
    "        input_ = torch.tensor([[result[-1]]]).to(device)  \n",
    "        log_probs, hidden_state = model(input_, hidden_state)\n",
    "\n",
    "        token_index = log_probs.argmax().item()\n",
    "        if token_index == vocab.stoi(end_token):\n",
    "            break\n",
    "        result.append(token_index)\n",
    "    return result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e74b936-a250-4971-b028-41a98eaae3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"vocab_size\": len(vocab),\n",
    "    \"embedding_dim\": 48,\n",
    "    \"context_size\": 5,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"num_epochs\": 20,\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "model = ElmanRnn(params[\"vocab_size\"], params[\"embedding_dim\"], params[\"hidden_dim\"])\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a18edc-bf13-42c5-a701-a929b5e8b73c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 429.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0833\n",
      "EPOCH : 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 629.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0168\n",
      "EPOCH : 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 573.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0126\n",
      "EPOCH : 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 580.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0114\n",
      "EPOCH : 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 589.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0110\n",
      "EPOCH : 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 622.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0107\n",
      "EPOCH : 6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 600.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0106\n",
      "EPOCH : 7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 561.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0105\n",
      "EPOCH : 8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 550.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0104\n",
      "EPOCH : 9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 521.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0104\n",
      "EPOCH : 10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 491.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0103\n",
      "EPOCH : 11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 555.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0103\n",
      "EPOCH : 12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 535.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0103\n",
      "EPOCH : 13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 585.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0103\n",
      "EPOCH : 14 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 599.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0103\n",
      "EPOCH : 15 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 602.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0103\n",
      "EPOCH : 16 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 568.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0102\n",
      "EPOCH : 17 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 560.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0102\n",
      "EPOCH : 18 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 464.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0102\n",
      "EPOCH : 19 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 605.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, tokens, vocab, params[\"context_size\"], loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fee0adc-d1e6-40b6-93d7-1a70e7bf7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '['\n",
    "end_token = ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d52e525d-b6f2-45c2-903d-92753e8f1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_token_ids = greedy_decode(model, vocab, start_token, end_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "747d89e9-d124-4c52-9407-41476096d66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [vocab[i] for i in generated_token_ids]\n",
    "\"\".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19ae4d82-94b8-4445-840e-56869e96f994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ElmanRnn(\n",
       "  (embeddings): Embedding(44, 48)\n",
       "  (W_h): Linear(in_features=48, out_features=256, bias=True)\n",
       "  (U_h): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (W_y): Linear(in_features=256, out_features=44, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "551d9613-ecc2-4153-ba99-2ca8d3c9a5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings.weight parameters to own_embeddings.weight.json\n",
      "Saved W_h.weight parameters to own_W_h.weight.json\n",
      "Saved W_h.bias parameters to own_W_h.bias.json\n",
      "Saved U_h.weight parameters to own_U_h.weight.json\n",
      "Saved U_h.bias parameters to own_U_h.bias.json\n",
      "Saved W_y.weight parameters to own_W_y.weight.json\n",
      "Saved W_y.bias parameters to own_W_y.bias.json\n",
      "Saved vocabulary to own_vocab.json\n",
      "Saved embeddings to own_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "def save_model_parameters(model, file_prefix=\"own\"):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:  \n",
    "            param_data = param.data.tolist()  \n",
    "            filename = f\"{file_prefix}_{name}.json\"\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(param_data, f)\n",
    "            print(f\"Saved {name} parameters to {filename}\")\n",
    "\n",
    "def save_vocab(vocab, filename=\"own_vocab.json\"):\n",
    "    vocab_data = vocab.tokens  \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(vocab_data, f)\n",
    "    print(f\"Saved vocabulary to {filename}\")\n",
    "\n",
    "def save_embeddings(embedding_layer, filename=\"own_embeddings.json\"):\n",
    "    embeddings = embedding_layer.weight.data.tolist() \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(embeddings, f)\n",
    "    print(f\"Saved embeddings to {filename}\")\n",
    "\n",
    "save_model_parameters(model)\n",
    "save_vocab(vocab)\n",
    "save_embeddings(model.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0768910e-5f31-4c8d-9cde-69727c9d8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solving own quest below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05f51f1c-4b0f-4ea7-93ca-fd0014594d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 48\n",
    "hidden_dim = 256\n",
    "vocab_size = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64291637-931f-4c30-a99a-a152885371e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_tensor(json_name):\n",
    "    with open(json_name, 'r') as file:\n",
    "        tensor = json.load(file)\n",
    "    return torch.tensor(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4252d83e-5d67-4875-8b1e-1446dfded203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 48])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_h_weight = json_to_tensor('own_W_h.weight.json')\n",
    "W_h_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dd5677a-daf7-40fe-9c60-56d414574694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 256])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_y_weight = json_to_tensor('own_W_y.weight.json')\n",
    "W_y_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da6644e4-d10c-4848-8c32-592e82079036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_h_weight = json_to_tensor('own_U_h.weight.json')\n",
    "U_h_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e4d761e-ae18-4eab-88d7-968d9feaa845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 48])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding_weight = json_to_tensor('own_embeddings.weight.json')\n",
    "Embedding_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80f598f8-7a1c-421b-af3c-957cc6d420a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('own_vocab.json', 'r') as file:\n",
    "    vocab = json.load(file)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd4d60b6-953c-4695-8bdd-0f68188a917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorElmanRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embeddings = Embedding_weight\n",
    "        self.W_h = W_h_weight\n",
    "        self.U_h = U_h_weight\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.h = torch.zeros(self.hidden_dim)\n",
    "        self.W_y = W_y_weight\n",
    "\n",
    "        \n",
    "    def forward(self, token_idx):\n",
    "        x = self.embeddings[token_idx]\n",
    "        h_t = self.tanh(self.W_h @ x + self.U_h @ self.h)\n",
    "        self.h = h_t\n",
    "        logits = self.W_y @ h_t\n",
    "        log_probs = torch.log_softmax(logits, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e2d4550-175a-4e28-98fe-331bcd630675",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = GeneratorElmanRnn(vocab_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f8103d5-2356-4edf-9016-671cd4240521",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \"[\"\n",
    "end_token = \"]\"\n",
    "@torch.no_grad()\n",
    "def greedy_decode_generative(model, vocab):\n",
    "    start_index = vocab.index(start_token)\n",
    "    result = [start_index]\n",
    "    while len(result) < 100:\n",
    "\n",
    "        input_ = result[-1]\n",
    "        log_probs = model(input_)\n",
    "\n",
    "        token_index = log_probs.argmax()\n",
    "\n",
    "        if token_index == vocab.index(end_token):\n",
    "            break\n",
    "\n",
    "        result.append(token_index.item())\n",
    "\n",
    "    return result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b74fca61-c8a8-4dca-8724-68a14be6dd19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_token_ids = greedy_decode_generative(gen_model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ee88cbd-b115-4bf8-9fb0-f4013070a11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Somewhere over the rainbow https://youtu.be/w_DKWlrA24k?si=xDJWHeC37RutylZX'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [vocab[i] for i in generated_token_ids]\n",
    "\"\".join(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
